{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35e8a366",
   "metadata": {},
   "source": [
    "# Import Libraries parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58812da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports & Global Config\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# === è³‡æ–™æ ¹ç›®éŒ„ ===\n",
    "BASE_DIR = os.getcwd()\n",
    "# or æ‰‹å‹•è¨­å®š\n",
    "# BASE_DIR = r\"C:\\Users\\User\\Desktop\\AICUP\"\n",
    "\n",
    "# Dataset ä¾†æºè³‡æ–™å¤¾\n",
    "#éœ€è¦æœ‰æ¯”è³½æä¾›çš„å…©è³‡æ–™å¤¾ : 42_training_image, 42_training_label\n",
    "SRC_IMG_ROOT = os.path.join(BASE_DIR, \"42_training_image\", \"training_image\")\n",
    "SRC_LBL_ROOT = os.path.join(BASE_DIR, \"42_training_label\", \"training_label\")\n",
    "\n",
    "# ç”¢ç”Ÿ ROI å¾Œçš„æ‰å¹³ YOLO dataset\n",
    "ROI_IMG_ROOT = os.path.join(BASE_DIR, \"roi_dataset\", \"images\")\n",
    "ROI_LBL_ROOT = os.path.join(BASE_DIR, \"roi_dataset\", \"labels\")\n",
    "\n",
    "# ROI å¾Œå†åš k-fold çš„ YOLO è³‡æ–™å¤¾\n",
    "#è«‹æ³¨æ„é€™è£¡æ¡ç”¨çš„æ–¹å¼çš†ç‚ºè¤‡è£½æª”æ¡ˆï¼Œå› æ­¤ç­‰æ–¼æœƒæœ‰ 1 (ROI) +5 (5fold) = 6å€çš„training data ä½”ç”¨ç©ºé–“ï¼Œé ˆæ³¨æ„ç¡¬ç¢Ÿç©ºé–“æ˜¯å¦è¶³å¤ \n",
    "KFOLD_ROOT = os.path.join(BASE_DIR, \"yolo_kfold_roi\")\n",
    "\n",
    "os.makedirs(ROI_IMG_ROOT, exist_ok=True)\n",
    "os.makedirs(ROI_LBL_ROOT, exist_ok=True)\n",
    "os.makedirs(KFOLD_ROOT, exist_ok=True)\n",
    "\n",
    "# å½±åƒå°ºå¯¸ (åŸå§‹ CT image å¤§å°)\n",
    "IMG_W = 512\n",
    "IMG_H = 512\n",
    "\n",
    "# === ROI è¨­å®š ===\n",
    "# ç¶“ç”±training data GT è¨ˆç®—è€Œä¾† ç„¡é ˆæ›´æ”¹ï¼š\n",
    "# åŸ x1_min â‰ˆ 130, y1_min â‰ˆ 183, x2_max â‰ˆ 287, y2_max â‰ˆ 352\n",
    "\n",
    "ROI_X1 = 100\n",
    "ROI_Y1 = 153\n",
    "ROI_X2 = 317\n",
    "ROI_Y2 = 382\n",
    "\n",
    "ROI_W = ROI_X2 - ROI_X1\n",
    "ROI_H = ROI_Y2 - ROI_Y1\n",
    "\n",
    "print(\"ROI:\", ROI_X1, ROI_Y1, \"â†’\", ROI_X2, ROI_Y2, \"(W,H)=(\", ROI_W, \",\", ROI_H, \")\")\n",
    "\n",
    "# === K-fold è¨­å®š ===\n",
    "N_FOLDS = 5\n",
    "SEED = 114514\n",
    "\n",
    "# === YOLO è¨“ç·´è¨­å®š ===\n",
    "MODEL_NAME = \"yolo12s.pt\" \n",
    "IMG_SIZE = 512\n",
    "EPOCHS = 45\n",
    "BATCH_SIZE = 64\n",
    "PROJECT = os.path.join(BASE_DIR, \"runs\", \"detect_kfold_roi\")\n",
    "\n",
    "os.makedirs(PROJECT, exist_ok=True)\n",
    "print(\"PROJECT:\", PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62bdc72",
   "metadata": {},
   "source": [
    "# Define tool functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b25eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def yolo_to_pixel(cx, cy, w, h, img_w, img_h):\n",
    "    \"\"\"YOLO normalized -> pixel box (x1,y1,x2,y2)\"\"\"\n",
    "    cx_px = cx * img_w\n",
    "    cy_px = cy * img_h\n",
    "    w_px = w * img_w\n",
    "    h_px = h * img_h\n",
    "    x1 = cx_px - w_px / 2\n",
    "    y1 = cy_px - h_px / 2\n",
    "    x2 = cx_px + w_px / 2\n",
    "    y2 = cy_px + h_px / 2\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def pixel_to_yolo(x1, y1, x2, y2, img_w, img_h):\n",
    "    \"\"\"pixel box (x1,y1,x2,y2) -> YOLO normalized (cx,cy,w,h)\"\"\"\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    cx = x1 + w / 2\n",
    "    cy = y1 + h / 2\n",
    "    return cx / img_w, cy / img_h, w / img_w, h / img_h\n",
    "\n",
    "def get_patient_id_from_path(path: str) -> str:\n",
    "    base = os.path.basename(path)\n",
    "    name = os.path.splitext(base)[0]\n",
    "    return name.split(\"_\")[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b840bd77",
   "metadata": {},
   "source": [
    "# Adding label.txt (with no coordinates) for background images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f863945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_all_images_have_labels(src_img_root, src_lbl_root):\n",
    "    \"\"\"\n",
    "    åœ¨ SRC_LBL_ROOT ä¸­ï¼Œç‚ºæ¯å¼µ PNG åœ–ç‰‡è£œä¸Šä¸€å€‹ç©ºç™½ txtï¼ˆå¦‚æœæ²’æœ‰çš„è©±ï¼‰\n",
    "    \"\"\"\n",
    "    cnt_new = 0\n",
    "    cnt_total = 0\n",
    "\n",
    "    patient_dirs = sorted(\n",
    "        d for d in os.listdir(src_img_root)\n",
    "        if os.path.isdir(os.path.join(src_img_root, d))\n",
    "    )\n",
    "\n",
    "    for pd in patient_dirs:\n",
    "        img_dir = os.path.join(src_img_root, pd)\n",
    "        lbl_dir = os.path.join(src_lbl_root, pd)\n",
    "        os.makedirs(lbl_dir, exist_ok=True)\n",
    "\n",
    "        img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.png\")))\n",
    "        for img_path in img_paths:\n",
    "            cnt_total += 1\n",
    "            base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            lbl_path = os.path.join(lbl_dir, base + \".txt\")\n",
    "            if not os.path.exists(lbl_path):\n",
    "   \n",
    "                open(lbl_path, \"w\", encoding=\"utf-8\").close()\n",
    "                cnt_new += 1\n",
    "\n",
    "    print(f\"ç¸½å…±æœ‰åœ–ç‰‡ {cnt_total} å¼µ\")\n",
    "    print(f\"è£œä¸Šæ–°çš„ç©ºç™½ label æª”æ¡ˆæ•¸ï¼š{cnt_new}\")\n",
    "\n",
    "seed_everything(SEED)\n",
    "ensure_all_images_have_labels(SRC_IMG_ROOT, SRC_LBL_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bb4451",
   "metadata": {},
   "source": [
    "# Create ROI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7087baa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ è™•ç† patient0009ï¼Œå…±æœ‰ 298 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0010ï¼Œå…±æœ‰ 280 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0011ï¼Œå…±æœ‰ 280 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0012ï¼Œå…±æœ‰ 372 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0013ï¼Œå…±æœ‰ 328 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0014ï¼Œå…±æœ‰ 280 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0015ï¼Œå…±æœ‰ 319 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0016ï¼Œå…±æœ‰ 427 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0017ï¼Œå…±æœ‰ 340 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0018ï¼Œå…±æœ‰ 289 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0019ï¼Œå…±æœ‰ 407 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0020ï¼Œå…±æœ‰ 270 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0021ï¼Œå…±æœ‰ 369 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0022ï¼Œå…±æœ‰ 291 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0023ï¼Œå…±æœ‰ 311 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0024ï¼Œå…±æœ‰ 355 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0025ï¼Œå…±æœ‰ 377 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0026ï¼Œå…±æœ‰ 289 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0027ï¼Œå…±æœ‰ 297 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0028ï¼Œå…±æœ‰ 313 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0029ï¼Œå…±æœ‰ 379 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0030ï¼Œå…±æœ‰ 399 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0031ï¼Œå…±æœ‰ 249 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0032ï¼Œå…±æœ‰ 292 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0033ï¼Œå…±æœ‰ 287 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0034ï¼Œå…±æœ‰ 391 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0035ï¼Œå…±æœ‰ 322 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0036ï¼Œå…±æœ‰ 281 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0037ï¼Œå…±æœ‰ 378 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0038ï¼Œå…±æœ‰ 395 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0039ï¼Œå…±æœ‰ 275 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0040ï¼Œå…±æœ‰ 378 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0041ï¼Œå…±æœ‰ 368 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0042ï¼Œå…±æœ‰ 389 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0043ï¼Œå…±æœ‰ 373 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0044ï¼Œå…±æœ‰ 360 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0045ï¼Œå…±æœ‰ 379 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0046ï¼Œå…±æœ‰ 403 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0047ï¼Œå…±æœ‰ 344 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0048ï¼Œå…±æœ‰ 377 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0049ï¼Œå…±æœ‰ 301 å¼µåœ–\n",
      "ğŸ“ è™•ç† patient0050ï¼Œå…±æœ‰ 392 å¼µåœ–\n",
      "\n",
      "ROI dataset ç”¢ç”Ÿå®Œæˆï¼\n",
      "ç¸½å…±è™•ç†åœ–ç‰‡æ•¸ï¼š16863\n",
      "ç¸½å…±ä¿ç•™ bbox æ•¸ï¼š2787\n",
      "ROI åœ–ç‰‡è¼¸å‡ºè·¯å¾‘ï¼šc:\\Users\\User\\Desktop\\AICUP2025\\roi_dataset\\images\n",
      "ROI label è¼¸å‡ºè·¯å¾‘ï¼šc:\\Users\\User\\Desktop\\AICUP2025\\roi_dataset\\labels\n"
     ]
    }
   ],
   "source": [
    "def process_one_pair_to_roi(img_path, lbl_path):\n",
    "    \"\"\"å°ä¸€å¼µåœ– + label åš ROI crop ä¸¦è¼¸å‡ºåˆ° ROI_IMG_ROOT / ROI_LBL_ROOT\"\"\"\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"âš  ç„¡æ³•è®€åœ–ï¼š{img_path}\")\n",
    "        return 0\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    if (h, w) != (IMG_H, IMG_W):\n",
    "        print(f\"âš  åœ–ç‰‡å°ºå¯¸ä¸æ˜¯ {IMG_W}x{IMG_H}ï¼š{img_path}ï¼ˆå¯¦éš› {w}x{h}ï¼‰ï¼Œä»ç„¶ç¹¼çºŒï¼Œä½†è«‹ç¢ºèª\")\n",
    "\n",
    "    x1, y1, x2, y2 = ROI_X1, ROI_Y1, ROI_X2, ROI_Y2\n",
    "    roi_img = img[y1:y2, x1:x2]\n",
    "\n",
    "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    dst_img_path = os.path.join(ROI_IMG_ROOT, base + \".png\")\n",
    "    dst_lbl_path = os.path.join(ROI_LBL_ROOT, base + \".txt\")\n",
    "\n",
    "    # å¯« ROI åœ–\n",
    "    cv2.imwrite(dst_img_path, roi_img)\n",
    "\n",
    "    # è®€ label\n",
    "    if not os.path.exists(lbl_path):\n",
    "        open(dst_lbl_path, \"w\", encoding=\"utf-8\").close()\n",
    "        return 0\n",
    "\n",
    "    with open(lbl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [ln.strip() for ln in f.readlines() if ln.strip()]\n",
    "\n",
    "    if not lines:\n",
    "        open(dst_lbl_path, \"w\", encoding=\"utf-8\").close()\n",
    "        return 0\n",
    "\n",
    "    new_lines = []\n",
    "    dropped = 0\n",
    "    for ln in lines:\n",
    "        parts = ln.split()\n",
    "        if len(parts) != 5:\n",
    "            print(f\"âš  é YOLO æ ¼å¼ï¼Œç•¥é: {lbl_path} -> {ln}\")\n",
    "            continue\n",
    "\n",
    "        cls_id = int(float(parts[0]))\n",
    "        cx_n, cy_n, w_n, h_n = map(float, parts[1:])\n",
    "\n",
    "        # åŸåœ– normalized -> pixel\n",
    "        x1_px, y1_px, x2_px, y2_px = yolo_to_pixel(cx_n, cy_n, w_n, h_n, IMG_W, IMG_H)\n",
    "\n",
    "        # å¹³ç§»åˆ° ROI åº§æ¨™ç³»\n",
    "        x1_roi = x1_px - ROI_X1\n",
    "        y1_roi = y1_px - ROI_Y1\n",
    "        x2_roi = x2_px - ROI_X1\n",
    "        y2_roi = y2_px - ROI_Y1\n",
    "\n",
    "        # clip åˆ° ROI å…§\n",
    "        x1_roi = max(0, min(ROI_W, x1_roi))\n",
    "        y1_roi = max(0, min(ROI_H, y1_roi))\n",
    "        x2_roi = max(0, min(ROI_W, x2_roi))\n",
    "        y2_roi = max(0, min(ROI_H, y2_roi))\n",
    "\n",
    "        if x2_roi <= x1_roi or y2_roi <= y1_roi:\n",
    "            dropped += 1\n",
    "            continue\n",
    "\n",
    "        # ROI pixel -> normalizedï¼ˆä»¥ ROI_W, ROI_H åŸºæº–ï¼‰\n",
    "        cx_roi_n, cy_roi_n, w_roi_n, h_roi_n = pixel_to_yolo(\n",
    "            x1_roi, y1_roi, x2_roi, y2_roi, ROI_W, ROI_H\n",
    "        )\n",
    "\n",
    "        cx_roi_n = min(max(cx_roi_n, 0.0), 1.0)\n",
    "        cy_roi_n = min(max(cy_roi_n, 0.0), 1.0)\n",
    "        w_roi_n  = min(max(w_roi_n,  0.0), 1.0)\n",
    "        h_roi_n  = min(max(h_roi_n,  0.0), 1.0)\n",
    "\n",
    "        new_lines.append(\n",
    "            f\"{cls_id} {cx_roi_n:.6f} {cy_roi_n:.6f} {w_roi_n:.6f} {h_roi_n:.6f}\"\n",
    "        )\n",
    "\n",
    "    with open(dst_lbl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for nl in new_lines:\n",
    "            f.write(nl + \"\\n\")\n",
    "\n",
    "    return len(new_lines)\n",
    "\n",
    "def build_roi_dataset():\n",
    "    total_imgs = 0\n",
    "    total_boxes = 0\n",
    "\n",
    "    patient_dirs = sorted(\n",
    "        d for d in os.listdir(SRC_IMG_ROOT)\n",
    "        if os.path.isdir(os.path.join(SRC_IMG_ROOT, d))\n",
    "    )\n",
    "\n",
    "    for pd in patient_dirs:\n",
    "        img_dir = os.path.join(SRC_IMG_ROOT, pd)\n",
    "        lbl_dir = os.path.join(SRC_LBL_ROOT, pd)\n",
    "        img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.png\")))\n",
    "        print(f\"ğŸ“ è™•ç† {pd}ï¼Œå…±æœ‰ {len(img_paths)} å¼µåœ–\")\n",
    "\n",
    "        for img_path in img_paths:\n",
    "            base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            lbl_path = os.path.join(lbl_dir, base + \".txt\")\n",
    "            n_box = process_one_pair_to_roi(img_path, lbl_path)\n",
    "            total_imgs += 1\n",
    "            total_boxes += n_box\n",
    "\n",
    "    print(\"\\nROI dataset ç”¢ç”Ÿå®Œæˆï¼\")\n",
    "    print(f\"ç¸½å…±è™•ç†åœ–ç‰‡æ•¸ï¼š{total_imgs}\")\n",
    "    print(f\"ç¸½å…±ä¿ç•™ bbox æ•¸ï¼š{total_boxes}\")\n",
    "    print(f\"ROI åœ–ç‰‡è¼¸å‡ºè·¯å¾‘ï¼š{ROI_IMG_ROOT}\")\n",
    "    print(f\"ROI label è¼¸å‡ºè·¯å¾‘ï¼š{ROI_LBL_ROOT}\")\n",
    "\n",
    "build_roi_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0331fd5c",
   "metadata": {},
   "source": [
    "# Create kfold YOLO folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31a3362e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åœ¨ ROI labels æ‰¾åˆ° 16863 å€‹æ¨™è¨»æª”\n",
      "å…±æ”¶é›†åˆ° 50 å€‹ç—…äºº\n",
      "patient0001 æ¨£æœ¬æ•¸ = 341\n",
      "patient0002 æ¨£æœ¬æ•¸ = 391\n",
      "patient0003 æ¨£æœ¬æ•¸ = 324\n",
      "patient0004 æ¨£æœ¬æ•¸ = 365\n",
      "patient0005 æ¨£æœ¬æ•¸ = 285\n"
     ]
    }
   ],
   "source": [
    "def collect_roi_by_patient():\n",
    "    \"\"\"\n",
    "    æƒæ ROI_LBL_ROOTï¼Œå»ºç«‹:\n",
    "      patient_to_files[pid] = [ (img_path, lbl_path), ... ]\n",
    "    \"\"\"\n",
    "    patient_to_files = defaultdict(list)\n",
    "\n",
    "    lbl_paths = sorted(glob.glob(os.path.join(ROI_LBL_ROOT, \"*.txt\")))\n",
    "    print(f\"åœ¨ ROI labels æ‰¾åˆ° {len(lbl_paths)} å€‹æ¨™è¨»æª”\")\n",
    "\n",
    "    for lbl_path in lbl_paths:\n",
    "        base = os.path.splitext(os.path.basename(lbl_path))[0]\n",
    "        img_path = os.path.join(ROI_IMG_ROOT, base + \".png\")\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"âš  æ‰¾ä¸åˆ°å°æ‡‰åœ–ç‰‡ï¼š{img_path}ï¼Œç•¥é\")\n",
    "            continue\n",
    "\n",
    "        pid = get_patient_id_from_path(lbl_path)\n",
    "        patient_to_files[pid].append((img_path, lbl_path))\n",
    "\n",
    "    print(f\"å…±æ”¶é›†åˆ° {len(patient_to_files)} å€‹ç—…äºº\")\n",
    "    return patient_to_files\n",
    "\n",
    "patient_to_files = collect_roi_by_patient()\n",
    "\n",
    "for pid, files in list(patient_to_files.items())[:5]:\n",
    "    print(pid, \"æ¨£æœ¬æ•¸ =\", len(files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a9d33",
   "metadata": {},
   "source": [
    "# Generate 5 FOLD dataset + data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c7eaa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç—…äººæ•¸é‡: 50\n",
      "\n",
      "=== Fold 1 ===\n",
      "Train ç—…äººæ•¸: 40\n",
      "Val   ç—…äººæ•¸: 10\n",
      "  Train å½±åƒæ•¸: 13280\n",
      "  Val   å½±åƒæ•¸: 3583\n",
      "âœ… å·²å»ºç«‹ c:\\Users\\User\\Desktop\\AICUP2025\\yolo_kfold_roi\\fold1\\fold1_data.yaml\n",
      "\n",
      "=== Fold 2 ===\n",
      "Train ç—…äººæ•¸: 40\n",
      "Val   ç—…äººæ•¸: 10\n",
      "  Train å½±åƒæ•¸: 13423\n",
      "  Val   å½±åƒæ•¸: 3440\n",
      "âœ… å·²å»ºç«‹ c:\\Users\\User\\Desktop\\AICUP2025\\yolo_kfold_roi\\fold2\\fold2_data.yaml\n",
      "\n",
      "=== Fold 3 ===\n",
      "Train ç—…äººæ•¸: 40\n",
      "Val   ç—…äººæ•¸: 10\n",
      "  Train å½±åƒæ•¸: 13492\n",
      "  Val   å½±åƒæ•¸: 3371\n",
      "âœ… å·²å»ºç«‹ c:\\Users\\User\\Desktop\\AICUP2025\\yolo_kfold_roi\\fold3\\fold3_data.yaml\n",
      "\n",
      "=== Fold 4 ===\n",
      "Train ç—…äººæ•¸: 40\n",
      "Val   ç—…äººæ•¸: 10\n",
      "  Train å½±åƒæ•¸: 13824\n",
      "  Val   å½±åƒæ•¸: 3039\n",
      "âœ… å·²å»ºç«‹ c:\\Users\\User\\Desktop\\AICUP2025\\yolo_kfold_roi\\fold4\\fold4_data.yaml\n",
      "\n",
      "=== Fold 5 ===\n",
      "Train ç—…äººæ•¸: 40\n",
      "Val   ç—…äººæ•¸: 10\n",
      "  Train å½±åƒæ•¸: 13433\n",
      "  Val   å½±åƒæ•¸: 3430\n",
      "âœ… å·²å»ºç«‹ c:\\Users\\User\\Desktop\\AICUP2025\\yolo_kfold_roi\\fold5\\fold5_data.yaml\n"
     ]
    }
   ],
   "source": [
    "def write_list_to_yolo_folder(file_list, dest_img_dir, dest_lbl_dir):\n",
    "    os.makedirs(dest_img_dir, exist_ok=True)\n",
    "    os.makedirs(dest_lbl_dir, exist_ok=True)\n",
    "\n",
    "    for img_src, lbl_src in file_list:\n",
    "        base = os.path.basename(img_src)\n",
    "        lbl_base = os.path.basename(lbl_src)\n",
    "\n",
    "        img_dst = os.path.join(dest_img_dir, base)\n",
    "        lbl_dst = os.path.join(dest_lbl_dir, lbl_base)\n",
    "\n",
    "        img = cv2.imread(img_src, cv2.IMREAD_UNCHANGED)\n",
    "        cv2.imwrite(img_dst, img)\n",
    "\n",
    "        with open(lbl_src, \"r\", encoding=\"utf-8\") as f_in, \\\n",
    "             open(lbl_dst, \"w\", encoding=\"utf-8\") as f_out:\n",
    "            f_out.write(f_in.read())\n",
    "\n",
    "def create_fold_datasets(n_folds=5, seed=42):\n",
    "    patients = sorted(patient_to_files.keys())\n",
    "    print(\"ç—…äººæ•¸é‡:\", len(patients))\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(patients), start=1):\n",
    "        train_pids = [patients[i] for i in train_idx]\n",
    "        val_pids   = [patients[i] for i in val_idx]\n",
    "\n",
    "        print(f\"\\n=== Fold {fold_idx} ===\")\n",
    "        print(\"Train ç—…äººæ•¸:\", len(train_pids))\n",
    "        print(\"Val   ç—…äººæ•¸:\", len(val_pids))\n",
    "\n",
    "        train_files = []\n",
    "        val_files = []\n",
    "\n",
    "        for pid in train_pids:\n",
    "            train_files.extend(patient_to_files[pid])\n",
    "        for pid in val_pids:\n",
    "            val_files.extend(patient_to_files[pid])\n",
    "\n",
    "        fold_dir = os.path.join(KFOLD_ROOT, f\"fold{fold_idx}\")\n",
    "        train_img_dir = os.path.join(fold_dir, \"train\", \"images\")\n",
    "        train_lbl_dir = os.path.join(fold_dir, \"train\", \"labels\")\n",
    "        val_img_dir   = os.path.join(fold_dir, \"val\", \"images\")\n",
    "        val_lbl_dir   = os.path.join(fold_dir, \"val\", \"labels\")\n",
    "\n",
    "        print(f\"  Train å½±åƒæ•¸: {len(train_files)}\")\n",
    "        print(f\"  Val   å½±åƒæ•¸: {len(val_files)}\")\n",
    "\n",
    "\n",
    "        write_list_to_yolo_folder(train_files, train_img_dir, train_lbl_dir)\n",
    "        write_list_to_yolo_folder(val_files,   val_img_dir,   val_lbl_dir)\n",
    "\n",
    "        # å»ºç«‹ data.yaml\n",
    "        data_yaml_path = os.path.join(fold_dir, f\"fold{fold_idx}_data.yaml\")\n",
    "        with open(data_yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"path: {fold_dir.replace(os.sep, '/')}\\n\")\n",
    "            f.write(\"train: train/images\\n\")\n",
    "            f.write(\"val: val/images\\n\")\n",
    "            f.write(\"names:\\n\")\n",
    "            f.write(\"  0: valve\\n\")\n",
    "\n",
    "        print(f\"âœ… å·²å»ºç«‹ {data_yaml_path}\")\n",
    "\n",
    "#é€™è£¡æ˜¯ç”¨è¤‡è£½çš„æ–¹å¼å»ºç«‹ k-fold dataset éœ€è¦ä¸€é»æ™‚é–“\n",
    "create_fold_datasets(N_FOLDS, SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ff603",
   "metadata": {},
   "source": [
    "# Training Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e333fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_fold(fold_idx: int):\n",
    "   \n",
    "    fold_dir  = os.path.join(KFOLD_ROOT, f\"fold{fold_idx}\")\n",
    "    data_yaml = os.path.join(fold_dir,  f\"fold{fold_idx}_data.yaml\")\n",
    "\n",
    "    if not os.path.exists(data_yaml):\n",
    "        print(f\"æ‰¾ä¸åˆ° {data_yaml}ï¼Œè«‹å…ˆè·‘ create_fold_datasets()\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\né–‹å§‹è¨“ç·´ Fold {fold_idx}\")\n",
    "    print(f\"   ä½¿ç”¨ data.yaml: {data_yaml}\")\n",
    "\n",
    "    model = YOLO(MODEL_NAME)\n",
    "\n",
    "    results = model.train(\n",
    "        data=data_yaml,\n",
    "        imgsz=IMG_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        batch=BATCH_SIZE,\n",
    "        device=0,          \n",
    "        workers=0,         \n",
    "        optimizer=\"AdamW\",\n",
    "        lr0=2e-5,\n",
    "        lrf=0.05,\n",
    "        patience=25,\n",
    "        cache=\"ram\",\n",
    "        amp=True,\n",
    "\n",
    "        mosaic=0.0,\n",
    "        copy_paste=0.0,\n",
    "        auto_augment=None,\n",
    "        erasing=0.0,\n",
    "        hsv_h=0.0,\n",
    "        hsv_s=0.0,\n",
    "        hsv_v=0.0,\n",
    "        fliplr=0.5,\n",
    "        flipud=0.0,\n",
    "\n",
    "        project=PROJECT,\n",
    "        name=f\"fold{fold_idx}_roi\",\n",
    "        exist_ok=True,\n",
    "        save_period=1,\n",
    "    )\n",
    "\n",
    "    print(f\"Fold {fold_idx} è¨“ç·´å®Œæˆï¼Œè¼¸å‡ºåœ¨ {PROJECT}/fold{fold_idx}_roi\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f16da3a",
   "metadata": {},
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68e4130c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "é–‹å§‹è¨“ç·´ Fold 1\n",
      "   ä½¿ç”¨ data.yaml: c:\\Users\\User\\Desktop\\AICUP2025\\yolo_kfold_roi\\fold1\\fold1_data.yaml\n",
      "New https://pypi.org/project/ultralytics/8.3.235 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.232  Python-3.13.9 torch-2.9.0+cu130 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 16303MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=None, batch=64, bgr=0.0, box=7.5, cache=ram, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=c:\\Users\\User\\Desktop\\AICUP2025\\yolo_kfold_roi\\fold1\\fold1_data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=45, erasing=0.0, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=2e-05, lrf=0.05, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12s.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=fold1_1024_roi, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=25, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=c:\\Users\\User\\Desktop\\AICUP2025\\runs\\detect_kfold_roi, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\Desktop\\AICUP2025\\runs\\detect_kfold_roi\\fold1_1024_roi, save_frames=False, save_json=False, save_period=1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n",
      " 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n",
      " 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 21        [14, 17, 20]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "YOLOv12s summary: 272 layers, 9,253,523 parameters, 9,253,507 gradients, 21.5 GFLOPs\n",
      "\n",
      "Transferred 685/691 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 6.5MB/s 0.8s.8s<0.0ss.9s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 6.41.8 MB/s, size: 21.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Desktop\\AICUP2025\\yolo_kfold_roi\\fold1\\train\\labels... 13280 images, 11075 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13280/13280 2.0Kit/s 6.6s<0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\User\\Desktop\\AICUP2025\\yolo_kfold_roi\\fold1\\train\\labels.cache\n",
      "WARNING cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (9.2GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13280/13280 5.6Kit/s 2.4s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 5.11.6 MB/s, size: 18.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\AICUP2025\\yolo_kfold_roi\\fold1\\val\\labels... 3583 images, 3001 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3583/3583 2.1Kit/s 1.7s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\User\\Desktop\\AICUP2025\\yolo_kfold_roi\\fold1\\val\\labels.cache\n",
      "WARNING cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (2.5GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3583/3583 4.4Kit/s 0.8s<0.0s\n",
      "Plotting labels to C:\\Users\\User\\Desktop\\AICUP2025\\runs\\detect_kfold_roi\\fold1_1024_roi\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=2e-05, momentum=0.937) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\User\\Desktop\\AICUP2025\\runs\\detect_kfold_roi\\fold1_1024_roi\u001b[0m\n",
      "Starting training for 45 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/45      13.3G      2.697      30.07      3.003         12        512: 8% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 17/208 3.8it/s 10.8s<49.7s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#å¯åªè·‘æŒ‡å®šå–®FOLD ä¾‹å¦‚:\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#train_one_fold(5)\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# æˆ–æ˜¯è¿´åœˆä¸€æ¬¡è·‘å…¨éƒ¨\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, N_FOLDS + \u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mtrain_one_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtrain_one_fold\u001b[39m\u001b[34m(fold_idx)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   ä½¿ç”¨ data.yaml: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_yaml\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m model = YOLO(MODEL_NAME)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_yaml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAdamW\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr0\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlrf\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mram\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmosaic\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy_paste\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_augment\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43merasing\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhsv_h\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhsv_s\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhsv_v\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfliplr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflipud\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPROJECT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfold\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_1024_roi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_period\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m è¨“ç·´å®Œæˆï¼Œè¼¸å‡ºåœ¨ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPROJECT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_1024_roi\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\ultralytics\\engine\\model.py:773\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    770\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m    771\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:243\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    240\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:427\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    425\u001b[39m     loss, \u001b[38;5;28mself\u001b[39m.loss_items = unwrap_model(\u001b[38;5;28mself\u001b[39m.model).loss(batch, preds)\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     loss, \u001b[38;5;28mself\u001b[39m.loss_items = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[38;5;28mself\u001b[39m.loss = loss.sum()\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK != -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:136\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Perform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[32m    124\u001b[39m \n\u001b[32m    125\u001b[39m \u001b[33;03mIf x is a dict, calculates and returns the loss for training. Otherwise, returns predictions for inference.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    133\u001b[39m \u001b[33;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predict(x, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:327\u001b[39m, in \u001b[36mBaseModel.loss\u001b[39m\u001b[34m(self, batch, preds)\u001b[39m\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m.criterion = \u001b[38;5;28mself\u001b[39m.init_criterion()\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     preds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.criterion(preds, batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:137\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss(x, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:154\u001b[39m, in \u001b[36mBaseModel.predict\u001b[39m\u001b[34m(self, x, profile, visualize, augment, embed)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._predict_augment(x)\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:176\u001b[39m, in \u001b[36mBaseModel._predict_once\u001b[39m\u001b[34m(self, x, profile, visualize, embed)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m._profile_one_layer(m, x, dt)\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m x = \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[32m    177\u001b[39m y.append(x \u001b[38;5;28;01mif\u001b[39;00m m.i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:1839\u001b[39m, in \u001b[36mA2C2f.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m   1837\u001b[39m y = [\u001b[38;5;28mself\u001b[39m.cv1(x)]\n\u001b[32m   1838\u001b[39m y.extend(m(y[-\u001b[32m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.m)\n\u001b[32m-> \u001b[39m\u001b[32m1839\u001b[39m y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1840\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gamma \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x + \u001b[38;5;28mself\u001b[39m.gamma.view(-\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.gamma.shape[\u001b[32m0\u001b[39m], \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m) * y\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:78\u001b[39m, in \u001b[36mConv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\u001b[39;00m\n\u001b[32m     71\u001b[39m \n\u001b[32m     72\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m \u001b[33;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.act(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:173\u001b[39m, in \u001b[36m_BatchNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.track_running_stats:\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.momentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[32m    175\u001b[39m             exponential_average_factor = \u001b[32m1.0\u001b[39m / \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_batches_tracked)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#å¯åªè·‘æŒ‡å®šå–®FOLD ä¾‹å¦‚:\n",
    "#train_one_fold(5)\n",
    "\n",
    "# æˆ–æ˜¯è¿´åœˆä¸€æ¬¡è·‘å…¨éƒ¨\n",
    "for k in range(1, N_FOLDS + 1):\n",
    "    train_one_fold(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
